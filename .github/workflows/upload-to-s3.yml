name: Upload dbt Files to S3

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  upload_files:
    runs-on: ubuntu-latest
    env:
      SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Install dbt
        run: |
          pip install dbt-core dbt-snowflake

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-northeast-1

      - name: Setup Snowflake private key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SNOWFLAKE_PRIVATE_KEY }}" > ~/.ssh/snowflake_tf_snow_key.p8
          chmod 600 ~/.ssh/snowflake_tf_snow_key.p8
          ls -la ~/.ssh
          echo "SNOWFLAKE_PRIVATE_KEY_PATH=$HOME/.ssh/snowflake_tf_snow_key.p8" >> $GITHUB_ENV

      - name: Run dbt docs generate
        run: |
          cd sample_project
          dbt deps
          dbt docs generate

      - name: Test AWS Connectivity
        run: |
            echo "Getting AWS caller identity:"
            aws sts get-caller-identity
            echo "Listing S3 buckets:"
            aws s3 ls
            echo "Listing contents of harato-trocco-dbt-snow bucket:"
            aws s3 ls s3://harato-trocco-dbt-snow/
    
      - name: Upload target directory to S3
        run: |
          aws s3 sync sample_project/target/ s3://harato-trocco-dbt-snow/ --acl private